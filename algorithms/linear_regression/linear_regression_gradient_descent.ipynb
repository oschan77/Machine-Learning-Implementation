{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNzIwm3AkcD99StwtJ51wtP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"7WvIt4t97xMI","executionInfo":{"status":"ok","timestamp":1691409882911,"user_tz":-480,"elapsed":2,"user":{"displayName":"Wanghin Chan","userId":"14848871187079720320"}}},"outputs":[],"source":["import numpy as np"]},{"cell_type":"code","source":["# X: (n, m)\n","# X_b: (n+1, m)\n","# y: (1, m)\n","# w: (n+1, 1)"],"metadata":{"id":"hS7Dh_vw4qCW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class LinearRegression:\n","    def __init__(self):\n","        self.n_epochs = 100\n","        self.lr = 0.1\n","\n","    def predict(self, w, X_b):\n","        return np.dot(w.T, X_b)\n","\n","    def cost_function(self, yhat, y, m):\n","        return 1 / m * np.sum(np.power(yhat - y, 2), axis=None)\n","\n","    def compute_grads(self, X, yhat, y, m):\n","        return 2 / m * np.dot(X, (yhat - y).T)\n","\n","    def main(self, X, y):\n","        n, m = X.shape[0], X.shape[1]\n","        bias = np.ones((1, m))\n","        X_b = np.append(bias, X, axis=0)\n","        w = np.zeros((n+1, 1))\n","\n","        for ep in range(self.n_epochs):\n","            yhat = self.predict(w, X_b)\n","            loss = self.cost_function(yhat, y, m)\n","            if ep%10 == 0:\n","                print(f'<ep{ep+1}> Loss: {loss}')\n","            grad = self.compute_grads(X_b, yhat, y, m)\n","            w -= self.lr * grad\n","\n","        print(f'<ep{ep+1}> Loss: {loss}')\n","        print(f'w_pred: {w}')\n","\n","if __name__ == \"__main__\":\n","    n_features = 4\n","    n_samples = 1000\n","    X = np.random.randn(n_features, n_samples)\n","    y = np.random.randn(1, n_samples) * 0.1\n","    for n in range(n_features):\n","        w_true = np.random.randint(1, 10)\n","        y += np.expand_dims(w_true * X[n,:], axis=0)\n","        print(f'w_true: {w_true}')\n","\n","    linReg = LinearRegression()\n","\n","    linReg.main(X, y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-dcuWBQd4xCR","executionInfo":{"status":"ok","timestamp":1691412316986,"user_tz":-480,"elapsed":3,"user":{"displayName":"Wanghin Chan","userId":"14848871187079720320"}},"outputId":"90177521-b32a-42f4-9bc8-d1003965795c"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["w_true: 5\n","w_true: 1\n","w_true: 2\n","w_true: 4\n","<ep1> Loss: 48.52660756982028\n","<ep11> Loss: 0.4438381276111491\n","<ep21> Loss: 0.013826606327175639\n","<ep31> Loss: 0.009697177178812992\n","<ep41> Loss: 0.009654013771512496\n","<ep51> Loss: 0.00965352146976937\n","<ep61> Loss: 0.009653515403915666\n","<ep71> Loss: 0.00965351532456235\n","<ep81> Loss: 0.009653515323479677\n","<ep91> Loss: 0.009653515323464486\n","<ep100> Loss: 0.009653515323464278\n","w_pred: [[0.00553572]\n"," [5.00529284]\n"," [1.00146575]\n"," [1.99638581]\n"," [3.99978089]]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Deo4xKak4ptw"},"execution_count":null,"outputs":[]}]}